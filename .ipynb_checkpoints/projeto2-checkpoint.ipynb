{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d707fc-9ca4-4325-8853-74d7554b9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer a versão 2.0 sem o 'try...except' das ofertas destacadas. Acho que isso está impedindo\n",
    "# que o driver acesse todas as páginas necessárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "ae6b0edb-3fb7-4e87-bcb8-6e39c9e02bd8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'casefold'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-595-85b8df0c2139>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Abacai'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Oi'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Lua'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcasefold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'casefold'"
     ]
    }
   ],
   "source": [
    "a = ['Abacai', 'Oi', 'Lua']\n",
    "\n",
    "a.casefold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "50dff7ac-9ba1-4d16-b64b-1e381541a51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['um', 'dois']"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Teste():\n",
    "            \n",
    "        \n",
    "    def __init__(self,lista):\n",
    "        self.list = Teste.case(lista)\n",
    "    \n",
    "    @staticmethod\n",
    "    def case(lista):\n",
    "        for element in lista:\n",
    "            lista[lista.index(element)] = element.casefold()\n",
    "        return lista\n",
    "        \n",
    "Teste(['Um', 'Dois']).list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "a2f2debb-eeba-447e-96ba-005a359ff7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 Version\n",
    "class GoogleShoppingQuery():\n",
    "    \n",
    "    def __init__(self, product, features, price_range, driver_path):\n",
    "        # string.\n",
    "        self.product = product\n",
    "        \n",
    "        # list.\n",
    "        self.features = features\n",
    "        \n",
    "        # tuple of numbers.\n",
    "        self.price_range = price_range\n",
    "        \n",
    "        # A string with your Chrome driver's path.\n",
    "        self.driver_path = driver_path\n",
    "        \n",
    "    # A partir daqui, criamos a funções de coleta de páginas de resultado e de avaliação de ofertas dentro\n",
    "    # da classe.\n",
    "    \n",
    "    def __collect_query_results(self):\n",
    "        # Esta função seria equivalente à 'get_query_pages', que está a algumas células abaixo.\n",
    "        # Como ela apenas fornece os insumos para a real extração dos dados, vamos colocar um '_' antes \n",
    "        # de seu nome.\n",
    "        # The 'output_pages' list will hold the link for all pages returned by the search bar query.\n",
    "        output_pages = []\n",
    "\n",
    "        # Making a query on Google Shopping for each product in the 'products' DF.\n",
    "\n",
    "        # Creating a Chrome Driver and accessing the Google Shopping page.\n",
    "        driver = webdriver.Chrome(self.driver_path)\n",
    "        driver.get('https://shopping.google.com.br/')\n",
    "\n",
    "        # Now, waiting for the website's search bar to appear.\n",
    "        try:    \n",
    "            search_bar = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"r7gAOb\"))\n",
    "                                )\n",
    "            # When the search bar is found, the program will write the product's name in the field and hit the RETURN key.\n",
    "            search_bar.send_keys(self.product)\n",
    "            search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "        # Since we must scrape all search results shown, it is necessary to use all the pages offered by Google Shopping.\n",
    "        # The page catalogue is stored as a HTML table.\n",
    "            try:\n",
    "                pages = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "                )\n",
    "\n",
    "                # Each page link that the table stores can be bound in its <td> tag.\n",
    "                page_link = pages.find_elements_by_tag_name('td') #.find_element_by_tag_name('a')\n",
    "\n",
    "                # Retrieving the links.\n",
    "                for page in page_link:\n",
    "                    a = page.find_elements_by_tag_name('a') #print(page.get_attribute('href'))\n",
    "\n",
    "                    # Some of the <td>'s do not have any <a> tag at all, so we are not going to append them into\n",
    "                    # the 'output_pages'. list.\n",
    "                    if a != []:\n",
    "                        output_pages.append(a[0].get_attribute('href'))\n",
    "            except:\n",
    "                driver.quit()\n",
    "        except:\n",
    "            driver.quit()\n",
    "\n",
    "        return output_pages\n",
    "    \n",
    "    def analyze_offers(self):\n",
    "        driver = webdriver.Chrome(self.driver_path)\n",
    "        min_price, max_price = self.price_range\n",
    "        target_products = pd.DataFrame({'Product':[],'Price':[],'Website URL':[]})\n",
    "        output_pages = self.__collect_query_results()\n",
    "        \n",
    "        #print(output_pages)\n",
    "        for page in output_pages:\n",
    "            print(page)\n",
    "            # Creating a Chrome Driver and accessing the Google Shopping page.\n",
    "            driver.get(page)\n",
    "            \n",
    "            # This whole 'try ... except' section is focused in looking upon the pages' highlighted offers.\n",
    "            # This was necessary because they are store in a <div> with a different class name from the rest of the merchandises.\n",
    "            try:\n",
    "                sponsored_offers = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"KZmu8e\"))\n",
    "                            )\n",
    "                sponsored_offers = driver.find_elements_by_class_name('KZmu8e')\n",
    "\n",
    "                # Finding the offers and getting their title.\n",
    "                for offer in sponsored_offers:\n",
    "                    offer_title = offer.find_element_by_class_name('sh-np__product-title').text.casefold()\n",
    "                    \n",
    "                    # Checking if the merchandise being offered has all the features we aim.\n",
    "                    if self.product in offer_title:\n",
    "                        # If a given desired attribute is not found in the offer's title, the\n",
    "                        # 'no_attribute_count' will be unequal to 0 and this will preclude the merhandise to be\n",
    "                        # attached to the 'target_products' DF.\n",
    "                        no_attribute_count = 0\n",
    "                        for attribute in self.features:\n",
    "                            if attribute not in offer_title:\n",
    "                                no_attribute_count +=1\n",
    "\n",
    "                        # If all the characteristics are found, we'll perform a second verification on the \n",
    "                        # offer, now seeing if its price is between the minimum and maximum values we've set.\n",
    "                        if no_attribute_count <1:\n",
    "                            \n",
    "                            # Doing this tiny 'try...except' because, contrary to our expectations, some of the offers\n",
    "                            # do not include their prices!\n",
    "                            try:\n",
    "                                price = float(offer.find_element_by_tag_name('b').text.split('R$ ')[1].replace('.','').replace(',','.'))\n",
    "                            except:\n",
    "                                continue\n",
    "                                \n",
    "                            # If that is the case, the offer's link is going to be extracted as well.\n",
    "                            # Then all we need to do is to attach the product's informations in the 'target_products' DF.\n",
    "                            if price in range(min_price, max_price+1):\n",
    "                                link = offer.find_element_by_class_name('shntl').get_attribute('href')\n",
    "                                target_products.loc[len(target_products)] = self.product, price, link\n",
    "            finally:\n",
    "                # Now, this part of the function will analyze only the pages' ordinay offers.\n",
    "                ordinary_offers = driver.find_elements_by_class_name('sh-dgr__content')\n",
    "                for offer in ordinary_offers:\n",
    "                    offer_title = offer.find_element_by_class_name('Xjkr3b').text.casefold()\n",
    "                    if self.product in offer_title:\n",
    "                        no_attribute_count = 0\n",
    "                        for attribute in self.features:\n",
    "                            if attribute not in offer_title:\n",
    "                                no_attribute_count +=1\n",
    "\n",
    "                        if no_attribute_count <1:\n",
    "                            price = float(offer.find_element_by_class_name('a8Pemb').text.split('R$ ')[1].replace('.','').replace(',','.')) #float(offer.find_element_by_class_name('a8Pemb').split('R$ ')[1].replace('.','').replace(',','.'))\n",
    "                            if price in range(min_price, max_price +1):\n",
    "                                link = offer.find_element_by_tag_name('a').get_attribute('href')\n",
    "                                target_products.loc[len(target_products)] = self.product, price, link\n",
    "                \n",
    "            return target_products\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "a395704b-db6d-41fc-91fe-9d5bff47db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 Version.\n",
    "class GoogleShoppingQuery():\n",
    "    \n",
    "    # This small static method puts the feature names to lowercase.\n",
    "    @staticmethod\n",
    "    def lower(features):\n",
    "        for feature in features:\n",
    "            features[features.index(feature)] = feature.casefold()\n",
    "        return features\n",
    "    \n",
    "    def __init__(self, product, features, price_range, driver_path):\n",
    "        # string.\n",
    "        self.product = product.casefold()\n",
    "        \n",
    "        # list.\n",
    "        self.features = GoogleShoppingQuery.lower(features)\n",
    "        \n",
    "        # tuple of numbers.\n",
    "        self.price_range = price_range\n",
    "        \n",
    "        # A string with your Chrome driver's path.\n",
    "        self.driver_path = driver_path\n",
    "\n",
    "    \n",
    "    # This function collects all the result pages from querying the product's name in Google Shopping.\n",
    "    def __collect_query_results(self):\n",
    "        \n",
    "        # The 'output_pages' list will hold the link for all pages returned by the search bar query.\n",
    "        output_pages = []\n",
    "\n",
    "        # Making a query on Google Shopping for each product in the 'products' DF.\n",
    "        driver = webdriver.Chrome(self.driver_path)\n",
    "        driver.get('https://shopping.google.com.br/')\n",
    "\n",
    "        # Now, waiting for the website's search bar to appear.\n",
    "        try:    \n",
    "            search_bar = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"r7gAOb\"))\n",
    "                                )\n",
    "            # When the search bar is found, the program will write the product's name in the field and hit the RETURN key.\n",
    "            search_bar.send_keys(self.product)\n",
    "            search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "        # The page catalogue is stored as an HTML table.\n",
    "            try:\n",
    "                pages = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "                )\n",
    "\n",
    "                # Each page link the table stores can be bound in its <td> tag.\n",
    "                page_link = pages.find_elements_by_tag_name('td') \n",
    "\n",
    "                # Retrieving the links.\n",
    "                for page in page_link:\n",
    "                    a = page.find_elements_by_tag_name('a') \n",
    "\n",
    "                    # Some of the <td>'s do not have any <a> tag at all, so we are not going to append them into \n",
    "                    # the 'output_pages'. list.\n",
    "                    if a != []:\n",
    "                        output_pages.append(a[0].get_attribute('href'))\n",
    "            except:\n",
    "                driver.quit()\n",
    "        except:\n",
    "            driver.quit()\n",
    "            \n",
    "        # The 'output_pages' is returned as the output from the function.\n",
    "        return output_pages\n",
    "    \n",
    "    # Now, this second method is going to be responsible for analyzing the offers from the pages identified by '__collect_query_results'\n",
    "    # and storing the appropriate one in a pandas DataFrame.\n",
    "    def analyze_offers(self):\n",
    "        driver = webdriver.Chrome(self.driver_path)\n",
    "        min_price, max_price = self.price_range\n",
    "        \n",
    "        # The DataFrame in which the convenient merchandises are placed.\n",
    "        target_products = pd.DataFrame({'Product':[],'Price':[],'Website URL':[]})\n",
    "        output_pages = self.__collect_query_results()\n",
    "        \n",
    "        for page in output_pages:\n",
    "            driver.get(page)\n",
    "            \n",
    "            # This whole 'try ... except' section is focused in looking upon the pages' highlighted offers.\n",
    "            # This was necessary because they are stored in a <div> with a different class name from the rest of the merchandises.\n",
    "            try:\n",
    "                sponsored_offers = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"KZmu8e\"))\n",
    "                            )\n",
    "                sponsored_offers = driver.find_elements_by_class_name('KZmu8e')\n",
    "\n",
    "                # Finding the offers and getting their title.\n",
    "                for offer in sponsored_offers:\n",
    "                    offer_title = offer.find_element_by_class_name('sh-np__product-title').text.casefold()\n",
    "                    \n",
    "                    # Checking if the merchandise being offered has all the features we are looking for.\n",
    "                    if self.product in offer_title:\n",
    "                        # If a given desired attribute is not found in the offer's title, the\n",
    "                        # 'no_attribute_count' will be unequal to 0. This will preclude the merhandise to be\n",
    "                        # attached to the 'target_products' DF.\n",
    "                        no_attribute_count = 0\n",
    "                        for attribute in self.features:\n",
    "                            if attribute not in offer_title:\n",
    "                                no_attribute_count +=1\n",
    "\n",
    "                        # If all the characteristics are found, we'll perform a second verification on the \n",
    "                        # offer, now seeing if its price is between the minimum and maximum values we've set.\n",
    "                        if no_attribute_count <1:\n",
    "                            \n",
    "                            # Doing this tiny 'try...except' because, contrary to our expectations, some of the offers\n",
    "                            # do not include their prices!\n",
    "                            try:\n",
    "                                price = float(offer.find_element_by_tag_name('b').text.split('R$ ')[1].replace('.','').replace(',','.'))\n",
    "                            except:\n",
    "                                continue\n",
    "                                \n",
    "                            # If that is the case, the offer's link is going to be extracted as well.\n",
    "                            # Then all we need to do is to attach the product's informations in the 'target_products' DF.\n",
    "                            if price in range(min_price, max_price+1):\n",
    "                                link = offer.find_element_by_class_name('shntl').get_attribute('href')\n",
    "                                target_products.loc[len(target_products)] = self.product, price, link\n",
    "            finally:\n",
    "                # Now, this part of the function will analyze only the pages' ordinay offers.\n",
    "                # Essentially, the same operations are performed as with the highlighted offers.\n",
    "                ordinary_offers = driver.find_elements_by_class_name('sh-dgr__content')\n",
    "                for offer in ordinary_offers:\n",
    "                    offer_title = offer.find_element_by_class_name('Xjkr3b').text.casefold()\n",
    "                    if self.product in offer_title:\n",
    "                        no_attribute_count = 0\n",
    "                        for attribute in self.features:\n",
    "                            if attribute not in offer_title:\n",
    "                                no_attribute_count +=1\n",
    "\n",
    "                        if no_attribute_count <1:\n",
    "                            try: \n",
    "                                price = float(offer.find_element_by_class_name('a8Pemb').text.split('R$ ')[1].replace('.','').replace(',','.')) #float(offer.find_element_by_class_name('a8Pemb').split('R$ ')[1].replace('.','').replace(',','.'))\n",
    "                            except:\n",
    "                                continue\n",
    "                            if price in range(min_price, max_price +1):\n",
    "                                link = offer.find_element_by_tag_name('a').get_attribute('href')\n",
    "                                target_products.loc[len(target_products)] = self.product, price, link       \n",
    "        return target_products\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "52ea1ea6-65b5-4da2-8eac-b13eeaada596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-593-e2570277a1b5>:75: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(self.driver_path)\n",
      "<ipython-input-593-e2570277a1b5>:37: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(self.driver_path)\n",
      "/Users/felipeveiga/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:359: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['64gb', 'vermelho']\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'counter' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-594-d82eeaa81af0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/Users/felipeveiga/Documents/Jupyter USP/Chrome Driver/chromedriver'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miphone12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGoogleShoppingQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'iphone 12'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'64gb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vermelho'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze_offers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-593-e2570277a1b5>\u001b[0m in \u001b[0;36manalyze_offers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_pages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m             \u001b[0;31m# Creating a Chrome Driver and accessing the Google Shopping page.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'counter' referenced before assignment"
     ]
    }
   ],
   "source": [
    "PATH = '/Users/felipeveiga/Documents/Jupyter USP/Chrome Driver/chromedriver'\n",
    "iphone12 = GoogleShoppingQuery('iphone 12', ['64gb', 'Vermelho'], (3500,4000), PATH ).analyze_offers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "eff60adf-5d65-4baa-936d-0b08f7b496da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.google.com.br/url?url=https://www.enjoei.com.br/p/iphone-12-apple-64gb-azul-tela-de-6-1-camera-69600466%3Fg_campaign%3Dgoogle_shopping&rct=j&q=&esrc=s&sa=U&ved=0ahUKEwi5jq3yiqr3AhXWjZUCHViaCvs4PBDVKQinDSgA&usg=AOvVaw2tnECEG1ZWEyD-e3xHZ_VK'"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone12.iloc[3,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1e659-6b35-44cd-a341-e4bbcf40092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'https://www.google.com.br/search?q=iphone+11&hl=pt-BR&psb=1&tbs=vw:d&tbm=shop&ei=s95jYo_bBoWY1sQP2YCu4AE&start=420&sa=N&ved=0ahUKEwjPgIKnhqr3AhUFjJUCHVmACxw4rAIQ8tMDCJQS&biw=1200&bih=529&dpr=1'\n",
    "b = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "24fcf9a4-c095-4aab-bc24-84b567966653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iphone 11</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>https://www.google.com.br/aclk?sa=l&amp;ai=DChcSEw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>iphone 11</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>https://www.google.com.br/aclk?sa=l&amp;ai=DChcSEw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iphone 11</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>https://www.google.com.br/aclk?sa=l&amp;ai=DChcSEw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iphone 11</td>\n",
       "      <td>3599.0</td>\n",
       "      <td>https://www.google.com.br/aclk?sa=l&amp;ai=DChcSEw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>iphone 11</td>\n",
       "      <td>3899.0</td>\n",
       "      <td>https://www.google.com.br/aclk?sa=l&amp;ai=DChcSEw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Product   Price                                        Website URL\n",
       "0  iphone 11  3699.0  https://www.google.com.br/aclk?sa=l&ai=DChcSEw...\n",
       "1  iphone 11  3699.0  https://www.google.com.br/aclk?sa=l&ai=DChcSEw...\n",
       "2  iphone 11  3600.0  https://www.google.com.br/aclk?sa=l&ai=DChcSEw...\n",
       "3  iphone 11  3599.0  https://www.google.com.br/aclk?sa=l&ai=DChcSEw...\n",
       "4  iphone 11  3899.0  https://www.google.com.br/aclk?sa=l&ai=DChcSEw..."
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links.iloc[0,2]\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b81da-403f-4ab1-ac37-1ad38ea12ec8",
   "metadata": {},
   "source": [
    "<h1 style='font-size:40px'>Python Web Automation Project</h1>\n",
    "<ul style='font-size:20px'> \n",
    "    <li>\n",
    "        Buying goods on the internet may be a very frustating experience. It may be difficult to find the product we aim to acquire with our desired specifications and an adequate price.\n",
    "    </li>\n",
    "    <li>\n",
    "        For such situations, Python can be an splendid tool for automating tasks that need to be done in the web.\n",
    "    </li>\n",
    "    <li>\n",
    "        In this project, we need to write a program that searches for two desired products on the internet. The websites to be used are Google Shopping and Buscapé.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be631ba8-a887-4cdf-a107-d455ae6db276",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('drive-download-20220405T163424Z-001.zip', 'r') as zip_file:\n",
    "    zip_file.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81957a00-7180-4706-a073-9f68f4076fd2",
   "metadata": {},
   "source": [
    "<ul style='font-size:20px'>\n",
    "    <li>\n",
    "        In the cell below, you can see the merchandises we would like to purchase. Looking to refine the query's results, a <em>Banned Key Words</em> column has been added in order to prevent the website to return different products by mistake. Also, a minimum and maximum prices have been set so that fraudulent products do not appear in the page. \n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ce13ea91-2433-4c6d-a24f-27649fc9f3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product Name</th>\n",
       "      <th>Further Details</th>\n",
       "      <th>Minimum Price</th>\n",
       "      <th>Maximum Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iphone 12</td>\n",
       "      <td>64gb</td>\n",
       "      <td>3000</td>\n",
       "      <td>3500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rtx 3060</td>\n",
       "      <td>12gb</td>\n",
       "      <td>4000</td>\n",
       "      <td>4500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Product Name Further Details  Minimum Price  Maximum Price\n",
       "0    iphone 12            64gb           3000           3500\n",
       "1     rtx 3060            12gb           4000           4500"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the sheet with the product informations we need.\n",
    "products = pd.read_csv('products.csv', sep=',', skipinitialspace=True)\n",
    "\n",
    "products#.loc[1,'Further Details'].split(';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d7e0d6e7-493c-46cc-9b45-b5dcea30a053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Product, Price, Website URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When Python discovers any offer that matches the criteria defined, it will store the product's\n",
    "# informations in the 'target_products' DF.\n",
    "target_products = pd.DataFrame({'Product':[],\n",
    "                              'Price':[],\n",
    "                              'Website URL':[]})\n",
    "target_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4c5018e7-018f-4d96-ac58-c96cd29dddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function below will retrive all the pages produced by querying the products' name in Google Shopping's website.\n",
    "def get_query_pages(products):\n",
    "\n",
    "    # The 'output_pages' list will hold the link for all pages returned by the search bar query.\n",
    "    output_pages = []\n",
    "    \n",
    "    # Making a query on Google Shopping for each product in the 'products' DF.\n",
    "    for product in products['Product Name']:\n",
    "\n",
    "        # Creating a Chrome Driver and accessing the Google Shopping page.\n",
    "        driver = webdriver.Chrome(PATH)\n",
    "        driver.get('https://shopping.google.com.br/')\n",
    "\n",
    "        # Now, waiting for the website's search bar to appear.\n",
    "        try:    \n",
    "            search_bar = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"r7gAOb\"))\n",
    "                                )\n",
    "            # When the search bar is found, the program will write the product's name in the field and hit the RETURN key.\n",
    "            search_bar.send_keys(product)\n",
    "            search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "        # Since we must scrape all search results shown, it is necessary to use all the pages offered by Google Shopping.\n",
    "        # The page catalogue is stored as a HTML table.\n",
    "            try:\n",
    "                pages = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.TAG_NAME, \"table\"))\n",
    "                )\n",
    "\n",
    "                # Each page link that the table stores can be bound in its <td> tag.\n",
    "                page_link = pages.find_elements_by_tag_name('td') #.find_element_by_tag_name('a')\n",
    "\n",
    "                # Retrieving the links.\n",
    "                for page in page_link:\n",
    "                    a = page.find_elements_by_tag_name('a') #print(page.get_attribute('href'))\n",
    "\n",
    "                    # Some of the <td>'s do not have any <a> tag at all, so we are not going to append them into\n",
    "                    # the 'output_pages'. list.\n",
    "                    if a != []:\n",
    "                        output_pages.append(a[0].get_attribute('href'))\n",
    "            except:\n",
    "                driver.quit()\n",
    "        except:\n",
    "            driver.quit()\n",
    "            \n",
    "    return output_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "a97c37eb-dbb6-438f-8d62-7aeee2ccb705",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Agora, criar uma função que 'scrape' as ofertas de cada página retornada por 'get_query_pages'.\n",
    "\n",
    "# Pegar o link dos produtos selecionados e colocá-los no DF.\n",
    "\n",
    "# Google Shopping queries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# This function will identify all offers from the highlighted section that are suit our demands.\n",
    "def highlighted(products, target_products):\n",
    "    PATH='/Users/felipeveiga/Documents/Jupyter USP/Chrome Driver/chromedriver'\n",
    "\n",
    "# Searching for the products using Google Shopping's search engine. \n",
    "    for product in products['Product Name']:\n",
    "        # Assigning each feature demanded and minimum and maximum prices to variables.\n",
    "        product_attributes = products[products['Product Name'] == product]['Further Details'].values[0].split(';')\n",
    "        min_price = products[products['Product Name'] == product]['Minimum Price'].values[0]\n",
    "        max_price = products[products['Product Name'] == product]['Maximum Price'].values[0]\n",
    "        \n",
    "        # Creating a Chrome Driver and accessing the Google Shopping page.\n",
    "        driver = webdriver.Chrome(PATH)\n",
    "        driver.get('https://shopping.google.com.br/')\n",
    "\n",
    "        # Looking for the search bar and inserting the product's name.\n",
    "        try:\n",
    "            search_bar = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"r7gAOb\"))\n",
    "                        )\n",
    "            search_bar.send_keys(product)\n",
    "            search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "            # When we hit RETURN, we'll wait the results page to be completely loaded in order\n",
    "            # to begin the data scraping.\n",
    "            try:\n",
    "                sponsored_offers = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"KZmu8e\"))\n",
    "                            )\n",
    "                sponsored_offers = driver.find_elements_by_class_name('KZmu8e')\n",
    "\n",
    "                # Finding the offers and getting their title.\n",
    "                for offer in sponsored_offers:\n",
    "                    offer_title = offer.find_element_by_class_name('sh-np__product-title').text.casefold()\n",
    "                    \n",
    "                    # Checking if the merchandise being offered has all the features we aim.\n",
    "                    if product in offer_title:\n",
    "                        # If a given desired attribute is not found in the offer's title, the\n",
    "                        # 'no_attribute_count' will be unequal to 0 and this will preclude the merhandise to be\n",
    "                        # attached to the 'target_products' DF.\n",
    "                        no_attribute_count = 0\n",
    "                        for attribute in product_attributes:\n",
    "                            if attribute not in offer_title:\n",
    "                                no_attribute_count +=1\n",
    "\n",
    "                        # If all the characteristics are found, we'll perform a second verification on the \n",
    "                        # offer, now seeing if its price is between the minimum and maximum values we've set.\n",
    "                        if no_attribute_count <1:\n",
    "                            price = float(offer.find_element_by_tag_name('b').text.split('R$ ')[1].replace('.','').replace(',','.'))\n",
    "\n",
    "                            # If that is the case, the offer's link is going to be extracted as well.\n",
    "                            # Then all we need to do is to attach the product's informations in the 'target_products' DF.\n",
    "                            if price in range(min_price, max_price+1):\n",
    "                                link = offer.find_element_by_class_name('shntl').get_attribute('href')\n",
    "                                target_products.loc[len(target_products)] = product, price, link\n",
    "            except:\n",
    "                driver.quit()\n",
    "\n",
    "        except:\n",
    "            driver.quit()\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "e7904c6e-e9a2-4e26-8290-d9a64bc32437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora, criar uma função que 'scrape' as ofertas de cada página retornada por 'get_query_pages'.\n",
    "\n",
    "# Pegar o link dos produtos selecionados e colocá-los no DF.\n",
    "\n",
    "# Google Shopping queries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# This function will identify all offers from the highlighted section that are suit our demands.\n",
    "def ordinary(products, target_products):\n",
    "    PATH='/Users/felipeveiga/Documents/Jupyter USP/Chrome Driver/chromedriver'\n",
    "\n",
    "# Searching for the products using Google Shopping's search engine. \n",
    "    for product in products['Product Name']:\n",
    "        # Assigning each feature demanded and minimum and maximum prices to variables.\n",
    "        product_attributes = products[products['Product Name'] == product]['Further Details'].values[0].split(';')\n",
    "        min_price = products[products['Product Name'] == product]['Minimum Price'].values[0]\n",
    "        max_price = products[products['Product Name'] == product]['Maximum Price'].values[0]\n",
    "        \n",
    "        # Creating a Chrome Driver and accessing the Google Shopping page.\n",
    "        driver = webdriver.Chrome(PATH)\n",
    "        driver.get('https://shopping.google.com.br/')\n",
    "\n",
    "        # Looking for the search bar and inserting the product's name.\n",
    "        try:\n",
    "            search_bar = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, \"r7gAOb\"))\n",
    "                        )\n",
    "            search_bar.send_keys(product)\n",
    "            search_bar.send_keys(Keys.RETURN)\n",
    "\n",
    "            # When we hit RETURN, we'll wait the results page to be completely loaded in order\n",
    "            # to begin the data scraping.\n",
    "            try:\n",
    "                ordinary_offers = WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, \"i0X6df\"))\n",
    "                            )\n",
    "                ordinary_offers = driver.find_elements_by_class_name('i0X6df')\n",
    "                #print(len(sponsored_offers))\n",
    "\n",
    "                # Finding the offers and getting their title.\n",
    "                for offer in ordinary_offers:\n",
    "                    offer_title = offer.find_element_by_class_name('Xjkr3b').text.casefold()\n",
    "                    #print(offer_title)\n",
    "                    \n",
    "                    # Checking if the merchandise being offered has all the features we aim.\n",
    "                    if product in offer_title:\n",
    "                        print(product, offer_title)\n",
    "                        # If a given desired attribute is not found in the offer's title, the\n",
    "                        # 'no_attribute_count' will be unequal to 0 and this will preclude the merhandise to be\n",
    "                        # attached to the 'target_products' DF.\n",
    "                        no_attribute_count = 0\n",
    "                        for attribute in product_attributes:\n",
    "                            if attribute not in offer_title:\n",
    "                                no_attribute_count +=1\n",
    "\n",
    "                        # If all the characteristics are found, we'll perform a second verification on the \n",
    "                        # offer, now seeing if its price is between the minimum and maximum values we've set.\n",
    "                        if no_attribute_count <1:\n",
    "                            price = float(offer.find_element_by_tag_name('b').text.split('R$ ')[1].replace('.','').replace(',','.'))\n",
    "                            print(price)\n",
    "                            \n",
    "                            # If that is the case, the offer's link is going to be extracted as well.\n",
    "                            # Then all we need to do is to attach the product's informations in the 'target_products' DF.\n",
    "                            if price in range(min_price, max_price+1):\n",
    "                                link = offer.find_element_by_class_name('Lq5OHe').get_attribute('href')\n",
    "                                target_products.loc[len(target_products)] = product, price, link\n",
    "            except:\n",
    "                pass\n",
    "                #driver.quit()\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "            #driver.quit()\n",
    "        \n",
    "        return target_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "cc160fbd-041e-4e73-9990-324fcf221b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-421-f5743655c66a>:24: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone 12 apple iphone 12, preto, 64gb, tela 6,1 pol. câm. dupla 12mp no plano vivo selfie ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-421-f5743655c66a>:41: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  ordinary_offers = driver.find_elements_by_class_name('i0X6df')\n",
      "/Users/felipeveiga/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:446: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "/Users/felipeveiga/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webelement.py:341: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Website URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Product, Price, Website URL]\n",
       "Index: []"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = pd.read_csv('products.csv', sep=',', skipinitialspace=True)\n",
    "target_products = pd.DataFrame({'Product':[],'Price':[],'Website URL':[]})\n",
    "ordinary(products, target_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e9460a35-2a0b-4bf2-bc3a-6c8c5bbb8b6d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-ebf6850fd41b>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iphone 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-ebf6850fd41b>:13: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  search_bar_candidates = driver.find_elements_by_tag_name('input')\n",
      "<ipython-input-109-ebf6850fd41b>:24: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  products_span = driver.find_elements_by_class_name('Cell_Name__pxLaW')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"fae64857-18d3-4935-af62-ebe7d7379d04\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"8791bba4-8d22-4262-94e6-def53e7f277a\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"7de753b9-48a8-4509-bd25-864889fe02c8\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"d6530122-49ec-4edc-9f06-4510505f6bbb\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"cbee4c71-4670-4841-8c3a-14adec41d083\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"ede2ce56-24c2-47f7-8cee-37c69e1747a9\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"1072995e-e371-4c0f-89a0-610278fe36b8\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"a5241b43-7fd4-4bfd-b45c-8ffd983a88ef\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"ee63caf3-d933-43e2-b11e-d357770400b8\")>, <selenium.webdriver.remote.webelement.WebElement (session=\"98bd6f0f51253aca3d797fa6704856dd\", element=\"040e9dab-23ff-4578-bb11-85e5d4c7c6e4\")>]\n",
      "h2 , Smartphone Apple iPhone 11 64GB iOS Câmera Dupla\n",
      "h2 , Smartphone Samsung Galaxy A12 SM-A125MZ 64GB Android\n",
      "h2 , Smartphone Samsung Galaxy M52 5G 128GB Android Câmera Tripla\n",
      "h2 , Ar-Condicionado Split LG 9000 BTUs Frio S4-Q09WA51\n",
      "h2 , Lavadora Brastemp 12kg BWK12AB\n",
      "h2 , Smartphone Xiaomi Redmi 9A 32GB Android 13.0 MP\n",
      "h2 , Smartphone Samsung Galaxy S20 FE SM-G780F 128GB Android\n",
      "h2 , Geladeira Brastemp BRO80AK Frost Free French Door Inverse 540 Litros Inox\n",
      "h2 , Smartphone Samsung Galaxy A32 SM-A325M 128GB Android\n",
      "h2 , Smartphone Apple iPhone 11 128GB iOS Câmera Dupla\n",
      "rtx 3060\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-ebf6850fd41b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# We'll split the label from the 'Product Name' column by word.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mproduct_properties\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcasefold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.buscape.com.br/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0msearch_bar_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_elements_by_tag_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#Then, the product name is going to be written in the Buscapé's search box.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \"\"\"\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{self._url}{path}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/selenium/webdriver/remote/remote_connection.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mstatuscode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     76\u001b[0m             )\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             return self.request_encode_body(\n\u001b[0m\u001b[1;32m     79\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/request.py\u001b[0m in \u001b[0;36mrequest_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mextra_kw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mredirect_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mredirect\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_redirect_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    443\u001b[0m                     \u001b[0;31m# Python 3 (including for exceptions like SystemExit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                     \u001b[0;31m# Otherwise it looks like a bug in the code.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1347\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1348\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Voltar depois aqui, os outputs estão muito esquisitos.\n",
    "# Entender o porquê de os outputs estarem errados.\n",
    "# Buscapé's queries.\n",
    "PATH='/Users/felipeveiga/Documents/Jupyter USP/Chrome Driver/chromedriver'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "# For product in the 'Product Name' column, a driver will be created.\n",
    "for product in products['Product Name']:\n",
    "    print(product)\n",
    "    # We'll split the label from the 'Product Name' column by word.\n",
    "    product_properties = product.casefold().split()\n",
    "    driver.get('https://www.buscape.com.br/')\n",
    "    search_bar_candidates = driver.find_elements_by_tag_name('input')\n",
    "    #Then, the product name is going to be written in the Buscapé's search box.\n",
    "    for thing in search_bar_candidates:    \n",
    "        # Finding the search box and performing a query in Buscapé's page\n",
    "        if thing.get_attribute('placeholder') == 'Digite sua busca...':\n",
    "            thing.send_keys(product)\n",
    "            thing.send_keys(Keys.RETURN)\n",
    "            try:\n",
    "                element = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"Cell_Name__pxLaW\"))\n",
    "                )\n",
    "                products_span = driver.find_elements_by_class_name('Cell_Name__pxLaW')\n",
    "                print(products_span)\n",
    "                for offer in products_span:\n",
    "                    title = offer.find_element_by_tag_name('h2')#.get_attribute('title').casefold()\n",
    "                    number_of_mismatches = 0\n",
    "                    print(title.tag_name, ',', title.text)\n",
    "                    for feature in product_properties:\n",
    "                        if feature not in title.text:\n",
    "                            number_of_mismatches +=1\n",
    "                        else:\n",
    "                            continue\n",
    "                    #if number_of_mismatches <1:\n",
    "                        #print(title)\n",
    "                    #else:\n",
    "                        #print(f'{title} não presta')\n",
    "            except:\n",
    "                print('Goodbye, World!')\n",
    "                #driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae287454-42b6-47fa-a01b-b9ba6c6ddb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-31504d3d2e1a>:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n",
      "<ipython-input-17-31504d3d2e1a>:4: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  search_bar_candidates = driver.find_elements_by_tag_name('input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "PATH='/Users/felipeveiga/Documents/Jupyter USP/Chrome Driver/chromedriver'\n",
    "driver = webdriver.Chrome(PATH)\n",
    "driver.get('https://www.buscape.com.br/')\n",
    "search_bar_candidates = driver.find_elements_by_tag_name('input')\n",
    "    #Then, the product name is going to be written in the Buscapé's search box.\n",
    "for thing in search_bar_candidates:    \n",
    "    # Finding the search box and performing a query in Buscapé's page\n",
    "    if thing.get_attribute('placeholder') == 'Digite sua busca...':\n",
    "        print('hi')\n",
    "        thing.send_keys('Iphone')\n",
    "        thing.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96aa592c-d85b-4c75-b7f4-0b9d8a22c1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '128gb'\n",
    "'12' in s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
